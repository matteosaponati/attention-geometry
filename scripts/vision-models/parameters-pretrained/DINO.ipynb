{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/attention-geometry/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.funs import count_parameters\n",
    "\n",
    "from transformers import ViTModel, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../../../_data/fig-parameters-vision-models/DINO.pkl'\n",
    "\n",
    "if os.path.isfile(dir):\n",
    "    with open(dir, 'rb') as file:\n",
    "        models = pickle.load(file)\n",
    "else: models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/homebrew/Caskroom/miniconda/base/envs/attention-geometry/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "'DINO small (l = 12, d = 384, h = 6, patches = 8 ; 21M parameters)'\n",
    "\n",
    "model = ViTModel.from_pretrained('facebook/dino-vits8')\n",
    "models['DINO-small-8'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINO base (l = 12, d = 768, h = 12, patches = 8 ; 85M parameters)'\n",
    "\n",
    "model = ViTModel.from_pretrained('facebook/dino-vitb8')\n",
    "models['DINO-base-8'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINO small (l = 6, d = 384, h = 6, patches = 16 ; 21M parameters)'\n",
    "\n",
    "model = ViTModel.from_pretrained('facebook/dino-vits16')\n",
    "models['DINO-small-16'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINO base (l = 12, d = 768, h = 12, patches = 16 ; 85M parameters)'\n",
    "\n",
    "model = ViTModel.from_pretrained('facebook/dino-vitb16')\n",
    "models['DINO-base-16'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINOv2 small (l = 6, d = 384, h = 6 ; 22.1M parameters)'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-small\")\n",
    "models['DINOv2-small'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINOv2 base (l = 12, d = 768, h = 12 ; 86.6M parameters)'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-base\")\n",
    "models['DINOv2-base'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINOv2 large (l = 24, d = 1024, h = 16 ; 304M parameters)'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-large\")\n",
    "models['DINOv2-large'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]\n",
    "\n",
    "'DINOv2 giant (l = 40, d = 1536, h = 24 ; 1140M parameters)'\n",
    "\n",
    "model = AutoModel.from_pretrained(\"facebook/dinov2-giant\")\n",
    "models['DINOv2-giant'] = [count_parameters(model), count_parameters(model, Embedding_FLAG = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'save'\n",
    "with open(dir, 'wb') as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
