{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from utils.funs import get_interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '../../../_data/fig-linear-self-attention/symmetric-dataset.pkl'\n",
    "\n",
    "if os.path.isfile(dir):\n",
    "    with open(dir, 'rb') as file:\n",
    "        models = pickle.load(file)\n",
    "else: models = {}\n",
    "\n",
    "data_path = '../../../_data/custom-models/symmetric-attention-from-scratch/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = 'symmetric-attention-from-scratch-final.csv'\n",
    "data = pd.read_csv(data_path + case, \n",
    "                       encoding='UTF-8', \n",
    "                       delimiter=',')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'name',\n",
       " 'state',\n",
       " 'id',\n",
       " 'Layer 0/Head 0 L2-Norm WqWk',\n",
       " 'Layer 0/Head 0 L2-Norm WvWo',\n",
       " 'Layer 0/Head 0 Symmetry WqWk',\n",
       " 'Layer 0/Head 0 Symmetry WvWo',\n",
       " 'Layer 0/Head 1 L2-Norm WqWk',\n",
       " 'Layer 0/Head 1 L2-Norm WvWo',\n",
       " 'Layer 0/Head 1 Symmetry WqWk',\n",
       " 'Layer 0/Head 1 Symmetry WvWo',\n",
       " 'Layer 0/Head 2 L2-Norm WqWk',\n",
       " 'Layer 0/Head 2 L2-Norm WvWo',\n",
       " 'Layer 0/Head 2 Symmetry WqWk',\n",
       " 'Layer 0/Head 2 Symmetry WvWo',\n",
       " 'Layer 0/Head 3 L2-Norm WqWk',\n",
       " 'Layer 0/Head 3 L2-Norm WvWo',\n",
       " 'Layer 0/Head 3 Symmetry WqWk',\n",
       " 'Layer 0/Head 3 Symmetry WvWo',\n",
       " 'Layer 1/Head 0 L2-Norm WqWk',\n",
       " 'Layer 1/Head 0 L2-Norm WvWo',\n",
       " 'Layer 1/Head 0 Symmetry WqWk',\n",
       " 'Layer 1/Head 0 Symmetry WvWo',\n",
       " 'Layer 1/Head 1 L2-Norm WqWk',\n",
       " 'Layer 1/Head 1 L2-Norm WvWo',\n",
       " 'Layer 1/Head 1 Symmetry WqWk',\n",
       " 'Layer 1/Head 1 Symmetry WvWo',\n",
       " 'Layer 1/Head 2 L2-Norm WqWk',\n",
       " 'Layer 1/Head 2 L2-Norm WvWo',\n",
       " 'Layer 1/Head 2 Symmetry WqWk',\n",
       " 'Layer 1/Head 2 Symmetry WvWo',\n",
       " 'Layer 1/Head 3 L2-Norm WqWk',\n",
       " 'Layer 1/Head 3 L2-Norm WvWo',\n",
       " 'Layer 1/Head 3 Symmetry WqWk',\n",
       " 'Layer 1/Head 3 Symmetry WvWo',\n",
       " 'Layer 2/Head 0 L2-Norm WqWk',\n",
       " 'Layer 2/Head 0 L2-Norm WvWo',\n",
       " 'Layer 2/Head 0 Symmetry WqWk',\n",
       " 'Layer 2/Head 0 Symmetry WvWo',\n",
       " 'Layer 2/Head 1 L2-Norm WqWk',\n",
       " 'Layer 2/Head 1 L2-Norm WvWo',\n",
       " 'Layer 2/Head 1 Symmetry WqWk',\n",
       " 'Layer 2/Head 1 Symmetry WvWo',\n",
       " 'Layer 2/Head 2 L2-Norm WqWk',\n",
       " 'Layer 2/Head 2 L2-Norm WvWo',\n",
       " 'Layer 2/Head 2 Symmetry WqWk',\n",
       " 'Layer 2/Head 2 Symmetry WvWo',\n",
       " 'Layer 2/Head 3 L2-Norm WqWk',\n",
       " 'Layer 2/Head 3 L2-Norm WvWo',\n",
       " 'Layer 2/Head 3 Symmetry WqWk',\n",
       " 'Layer 2/Head 3 Symmetry WvWo',\n",
       " 'Layer 3/Head 0 L2-Norm WqWk',\n",
       " 'Layer 3/Head 0 L2-Norm WvWo',\n",
       " 'Layer 3/Head 0 Symmetry WqWk',\n",
       " 'Layer 3/Head 0 Symmetry WvWo',\n",
       " 'Layer 3/Head 1 L2-Norm WqWk',\n",
       " 'Layer 3/Head 1 L2-Norm WvWo',\n",
       " 'Layer 3/Head 1 Symmetry WqWk',\n",
       " 'Layer 3/Head 1 Symmetry WvWo',\n",
       " 'Layer 3/Head 2 L2-Norm WqWk',\n",
       " 'Layer 3/Head 2 L2-Norm WvWo',\n",
       " 'Layer 3/Head 2 Symmetry WqWk',\n",
       " 'Layer 3/Head 2 Symmetry WvWo',\n",
       " 'Layer 3/Head 3 L2-Norm WqWk',\n",
       " 'Layer 3/Head 3 L2-Norm WvWo',\n",
       " 'Layer 3/Head 3 Symmetry WqWk',\n",
       " 'Layer 3/Head 3 Symmetry WvWo',\n",
       " 'Overall Symmetry/Max Symmetry WqWk',\n",
       " 'Overall Symmetry/Max Symmetry WvWo',\n",
       " 'Overall Symmetry/Mean Symmetry WqWk',\n",
       " 'Overall Symmetry/Mean Symmetry WvWo',\n",
       " 'Overall Symmetry/Median Symmetry WqWk',\n",
       " 'Overall Symmetry/Median Symmetry WvWo',\n",
       " 'Overall Symmetry/Min Symmetry WqWk',\n",
       " 'Overall Symmetry/Min Symmetry WvWo',\n",
       " 'Overall Symmetry/Variance Symmetry WqWk',\n",
       " 'Overall Symmetry/Variance Symmetry WvWo',\n",
       " '_runtime',\n",
       " '_step',\n",
       " '_timestamp',\n",
       " '_wandb',\n",
       " 'gamma L=0',\n",
       " 'gamma L=1',\n",
       " 'gamma L=2',\n",
       " 'gamma L=3',\n",
       " 'lm_loss',\n",
       " 'reg_loss',\n",
       " 'reg_loss L=0',\n",
       " 'reg_loss L=0 H=0',\n",
       " 'reg_loss L=0 H=1',\n",
       " 'reg_loss L=0 H=2',\n",
       " 'reg_loss L=0 H=3',\n",
       " 'reg_loss L=1',\n",
       " 'reg_loss L=1 H=0',\n",
       " 'reg_loss L=1 H=1',\n",
       " 'reg_loss L=1 H=2',\n",
       " 'reg_loss L=1 H=3',\n",
       " 'reg_loss L=2',\n",
       " 'reg_loss L=2 H=0',\n",
       " 'reg_loss L=2 H=1',\n",
       " 'reg_loss L=2 H=2',\n",
       " 'reg_loss L=2 H=3',\n",
       " 'reg_loss L=3',\n",
       " 'reg_loss L=3 H=0',\n",
       " 'reg_loss L=3 H=1',\n",
       " 'reg_loss L=3 H=2',\n",
       " 'reg_loss L=3 H=3',\n",
       " 'total_flos',\n",
       " 'total_loss',\n",
       " 'train/epoch',\n",
       " 'train/global_step',\n",
       " 'train/grad_norm',\n",
       " 'train/learning_rate',\n",
       " 'train/loss',\n",
       " 'train_loss',\n",
       " 'train_runtime',\n",
       " 'train_samples_per_second',\n",
       " 'train_steps_per_second',\n",
       " 'bf16',\n",
       " 'fp16',\n",
       " 'fsdp',\n",
       " 'seed',\n",
       " 'tf32',\n",
       " 'debug',\n",
       " 'optim',\n",
       " 'top_k',\n",
       " 'top_p',\n",
       " 'prefix',\n",
       " 'do_eval',\n",
       " 'no_cuda',\n",
       " 'use_cpu',\n",
       " 'do_train',\n",
       " 'id2label',\n",
       " 'label2id',\n",
       " 'run_name',\n",
       " 'use_ipex',\n",
       " 'adafactor',\n",
       " 'data_seed',\n",
       " 'deepspeed',\n",
       " 'do_sample',\n",
       " 'hub_token',\n",
       " 'log_level',\n",
       " 'max_steps',\n",
       " 'num_beams',\n",
       " 'ray_scope',\n",
       " 'report_to',\n",
       " 'typical_p',\n",
       " 'use_cache',\n",
       " 'adam_beta1',\n",
       " 'adam_beta2',\n",
       " 'do_predict',\n",
       " 'eval_delay',\n",
       " 'eval_steps',\n",
       " 'hidden_act',\n",
       " 'is_decoder',\n",
       " 'local_rank',\n",
       " 'max_length',\n",
       " 'min_length',\n",
       " 'model_type',\n",
       " 'optim_args',\n",
       " 'output_dir',\n",
       " 'past_index',\n",
       " 'save_steps',\n",
       " 'vocab_size',\n",
       " 'ddp_backend',\n",
       " 'ddp_timeout',\n",
       " 'fsdp_config',\n",
       " 'hidden_size',\n",
       " 'label_names',\n",
       " 'logging_dir',\n",
       " 'push_to_hub',\n",
       " 'return_dict',\n",
       " 'temperature',\n",
       " 'torch_dtype',\n",
       " 'torchdynamo',\n",
       " 'torchscript',\n",
       " 'adam_epsilon',\n",
       " 'bos_token_id',\n",
       " 'disable_tqdm',\n",
       " 'eos_token_id',\n",
       " 'fp16_backend',\n",
       " 'hub_model_id',\n",
       " 'hub_strategy',\n",
       " 'pad_token_id',\n",
       " 'problem_type',\n",
       " 'pruned_heads',\n",
       " 'sep_token_id',\n",
       " 'use_bfloat16',\n",
       " 'warmup_ratio',\n",
       " 'warmup_steps',\n",
       " 'weight_decay',\n",
       " '_name_or_path',\n",
       " 'architectures',\n",
       " 'bad_words_ids',\n",
       " 'jit_mode_eval',\n",
       " 'learning_rate',\n",
       " 'logging_steps',\n",
       " 'max_grad_norm',\n",
       " 'mp_parameters',\n",
       " 'output_scores',\n",
       " 'save_strategy',\n",
       " 'split_batches',\n",
       " 'torch_compile',\n",
       " 'tpu_num_cores',\n",
       " 'bf16_full_eval',\n",
       " 'early_stopping',\n",
       " 'fp16_full_eval',\n",
       " 'fp16_opt_level',\n",
       " 'layer_norm_eps',\n",
       " 'length_penalty',\n",
       " 'tf_legacy_loss',\n",
       " 'use_mps_device',\n",
       " 'finetuning_task',\n",
       " 'group_by_length',\n",
       " 'hub_always_push',\n",
       " 'num_beam_groups',\n",
       " 'save_only_model',\n",
       " 'suppress_tokens',\n",
       " 'tokenizer_class',\n",
       " 'type_vocab_size',\n",
       " 'dispatch_batches',\n",
       " 'full_determinism',\n",
       " 'hub_private_repo',\n",
       " 'ignore_data_skip',\n",
       " 'log_on_each_node',\n",
       " 'logging_strategy',\n",
       " 'num_train_epochs',\n",
       " 'save_safetensors',\n",
       " 'save_total_limit',\n",
       " 'ddp_bucket_cap_mb',\n",
       " 'diversity_penalty',\n",
       " 'greater_is_better',\n",
       " 'initializer_range',\n",
       " 'intermediate_size',\n",
       " 'log_level_replica',\n",
       " 'lr_scheduler_type',\n",
       " 'num_hidden_layers',\n",
       " 'output_attentions',\n",
       " 'push_to_hub_token',\n",
       " 'save_on_each_node',\n",
       " 'tpu_metrics_debug',\n",
       " 'accelerator_config',\n",
       " 'classifier_dropout',\n",
       " 'is_encoder_decoder',\n",
       " 'length_column_name',\n",
       " 'logging_first_step',\n",
       " 'repetition_penalty',\n",
       " 'torch_compile_mode',\n",
       " 'add_cross_attention',\n",
       " 'evaluation_strategy',\n",
       " 'forced_bos_token_id',\n",
       " 'forced_eos_token_id',\n",
       " 'fsdp_min_num_params',\n",
       " 'hidden_dropout_prob',\n",
       " 'lr_scheduler_kwargs',\n",
       " 'neftune_noise_alpha',\n",
       " 'num_attention_heads',\n",
       " 'skip_memory_metrics',\n",
       " 'tie_encoder_decoder',\n",
       " 'tie_word_embeddings',\n",
       " 'auto_find_batch_size',\n",
       " 'dataloader_drop_last',\n",
       " 'no_repeat_ngram_size',\n",
       " 'num_return_sequences',\n",
       " 'optim_target_modules',\n",
       " 'output_hidden_states',\n",
       " 'overwrite_output_dir',\n",
       " 'prediction_loss_only',\n",
       " 'push_to_hub_model_id',\n",
       " 'task_specific_params',\n",
       " 'transformers_version',\n",
       " 'begin_suppress_tokens',\n",
       " 'dataloader_pin_memory',\n",
       " 'ddp_broadcast_buffers',\n",
       " 'metric_for_best_model',\n",
       " 'remove_invalid_values',\n",
       " 'remove_unused_columns',\n",
       " 'torch_compile_backend',\n",
       " 'dataloader_num_workers',\n",
       " 'decoder_start_token_id',\n",
       " 'gradient_checkpointing',\n",
       " 'half_precision_backend',\n",
       " 'label_smoothing_factor',\n",
       " 'load_best_model_at_end',\n",
       " 'logging_nan_inf_filter',\n",
       " 'resume_from_checkpoint',\n",
       " 'chunk_size_feed_forward',\n",
       " 'eval_accumulation_steps',\n",
       " 'max_position_embeddings',\n",
       " 'per_gpu_eval_batch_size',\n",
       " 'position_embedding_type',\n",
       " 'return_dict_in_generate',\n",
       " 'per_gpu_train_batch_size',\n",
       " 'push_to_hub_organization',\n",
       " 'include_tokens_per_second',\n",
       " 'dataloader_prefetch_factor',\n",
       " 'ddp_find_unused_parameters',\n",
       " 'include_inputs_for_metrics',\n",
       " 'per_device_eval_batch_size',\n",
       " 'use_legacy_prediction_loop',\n",
       " 'cross_attention_hidden_size',\n",
       " 'gradient_accumulation_steps',\n",
       " 'per_device_train_batch_size',\n",
       " 'attention_probs_dropout_prob',\n",
       " 'encoder_no_repeat_ngram_size',\n",
       " 'dataloader_persistent_workers',\n",
       " 'gradient_checkpointing_kwargs',\n",
       " 'include_num_input_tokens_seen',\n",
       " 'exponential_decay_length_penalty',\n",
       " 'fsdp_transformer_layer_cls_to_wrap',\n",
       " 'masked_lm_loss']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>train/loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bert_small--decoder-custom-loss(5)--red_pajama</td>\n",
       "      <td>2.0539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bert_small--encoder-custom-loss(5)--red_pajama</td>\n",
       "      <td>1.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bert_small--encoder-custom-loss(10)--red_pajama</td>\n",
       "      <td>1.2463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bert_small--decoder-custom-loss(10)--red_pajama</td>\n",
       "      <td>2.3355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bert_small--decoder-custom-loss(0)--red_pajama</td>\n",
       "      <td>2.5210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>bert_small--encoder-custom-loss(0)--red_pajama</td>\n",
       "      <td>1.0993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bert_small--encoder-custom-loss(5)--red_pajama</td>\n",
       "      <td>1.1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>bert_small--decoder--red_pajama--skew-symmetri...</td>\n",
       "      <td>2.0306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>bert_small--encoder--red_pajama--skew-symmetri...</td>\n",
       "      <td>0.9433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>bert_small--decoder--red_pajama--symmetric-init</td>\n",
       "      <td>2.0311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>bert_small--encoder--red_pajama--symmetric-init</td>\n",
       "      <td>0.9098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bert_small--decoder--red_pajama</td>\n",
       "      <td>2.0459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>bert_small--encoder--red_pajama</td>\n",
       "      <td>1.1087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name  train/loss\n",
       "0      bert_small--decoder-custom-loss(5)--red_pajama      2.0539\n",
       "1      bert_small--encoder-custom-loss(5)--red_pajama      1.1094\n",
       "2     bert_small--encoder-custom-loss(10)--red_pajama      1.2463\n",
       "3     bert_small--decoder-custom-loss(10)--red_pajama      2.3355\n",
       "4      bert_small--decoder-custom-loss(0)--red_pajama      2.5210\n",
       "5      bert_small--encoder-custom-loss(0)--red_pajama      1.0993\n",
       "6      bert_small--encoder-custom-loss(5)--red_pajama      1.1093\n",
       "7   bert_small--decoder--red_pajama--skew-symmetri...      2.0306\n",
       "8   bert_small--encoder--red_pajama--skew-symmetri...      0.9433\n",
       "9     bert_small--decoder--red_pajama--symmetric-init      2.0311\n",
       "10    bert_small--encoder--red_pajama--symmetric-init      0.9098\n",
       "11                    bert_small--decoder--red_pajama      2.0459\n",
       "12                    bert_small--encoder--red_pajama      1.1087"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['name', 'train/loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
