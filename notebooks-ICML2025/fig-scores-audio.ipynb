{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "plt.rc('axes', axisbelow=True)\n",
    "\n",
    "from utils.visualization import plot_median_scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "with open('../_results/audio-models/SpeechT5Encoder.pkl', 'rb') as file:\n",
    "    SpeechT5Encoder = pickle.load(file)\n",
    "with open('../_results/audio-models/MusicGenEncoder.pkl', 'rb') as file:\n",
    "    MusicGenEncoder = pickle.load(file)\n",
    "with open('../_results/audio-models/HUBERT.pkl', 'rb') as file:\n",
    "    HUBERT = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/s2t.pkl', 'rb') as file:\n",
    "    s2t = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/unispeech.pkl', 'rb') as file:\n",
    "    unispeech = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/wavlm.pkl', 'rb') as file:\n",
    "    wavlm = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/whisper-encoder.pkl', 'rb') as file:\n",
    "    whisper_enc = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/whisperv2-encoder.pkl', 'rb') as file:\n",
    "    whisperV2_enc = pickle.load(file)\n",
    "with open('attention-geometry/_results/audio-models/whisperv3-encoder.pkl', 'rb') as file:\n",
    "    whisperV3_enc = pickle.load(file)\n",
    "\n",
    "with open('../_results/audio-models/SpeechT5Decoder.pkl', 'rb') as file:\n",
    "    SpeechT5Decoder = pickle.load(file)\n",
    "with open('../_results/audio-models/MusicGenDecoder.pkl', 'rb') as file:\n",
    "    MusicGenDecoder = pickle.load(file)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plot_median_scores(SpeechT5Encoder, color = 'navy')\n",
    "plot_median_scores(MusicGenEncoder, color = 'navy')\n",
    "plot_median_scores(HUBERT, color = 'navy')\n",
    "plot_median_scores(s2t, color = 'navy')\n",
    "plot_median_scores(unispeech, color = 'navy')\n",
    "plot_median_scores(wavlm, color = 'navy')\n",
    "plot_median_scores(whisper_enc, color = 'navy')\n",
    "plot_median_scores(whisperV2_enc, color = 'navy')\n",
    "plot_median_scores(whisperV3_enc, color = 'navy')\n",
    "\n",
    "plot_median_scores(SpeechT5Decoder, color = 'purple')\n",
    "plot_median_scores(MusicGenDecoder, color = 'purple')\n",
    "\n",
    "plt.axhline(y=0,linestyle='dashed',color='k')\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5)\n",
    "plt.xscale('log')\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(10e5, 10e11)\n",
    "plt.ylabel('symmetry score')\n",
    "plt.xlabel('# parameters')\n",
    "\n",
    "plt.savefig('figures/fig-symmetry-audio.pdf', format='pdf', dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plot_median_scores(SpeechT5Encoder, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(MusicGenEncoder, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(HUBERT, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(s2t, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(unispeech, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(wavlm, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(whisper_enc, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(whisperV2_enc, color = 'navy', mode = 'directionality')\n",
    "plot_median_scores(whisperV3_enc, color = 'navy', mode = 'directionality')\n",
    "\n",
    "plot_median_scores(SpeechT5Decoder, color = 'purple', mode = 'directionality')\n",
    "plot_median_scores(MusicGenDecoder, color = 'purple', mode = 'directionality')\n",
    "\n",
    "plt.axhline(y=0,linestyle='dashed',color='k')\n",
    "plt.grid(color = 'gray', linestyle = '--', linewidth = 0.5)\n",
    "plt.xscale('log')\n",
    "plt.ylim(-1,1)\n",
    "plt.xlim(10e5, 10e11)\n",
    "plt.ylabel('directionality score')\n",
    "plt.xlabel('# parameters')\n",
    "\n",
    "plt.savefig('figures/fig-directionality-audio.pdf', format='pdf', dpi=300)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
