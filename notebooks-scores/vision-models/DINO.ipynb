{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/attention-geometry/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "from transformers import ViTModel, AutoConfig\n",
    "from utils.funs import create_dict\n",
    "from utils.scores import get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, dir = create_dict('vision-models', 'DINO.pkl')\n",
    "\n",
    "path = [\"encoder.layer[\", \n",
    "        \"].attention.attention.query.weight\", \n",
    "        \"].attention.attention.key.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb8 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/attention-geometry/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vits16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dino-vitb16 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type dinov2 to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dinov2-small and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type dinov2 to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dinov2-base and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type dinov2 to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dinov2-large and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.layernorm_after.bias', 'encoder.layer.12.layernorm_after.weight', 'encoder.layer.12.layernorm_before.bias', 'encoder.layer.12.layernorm_before.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.layernorm_after.bias', 'encoder.layer.13.layernorm_after.weight', 'encoder.layer.13.layernorm_before.bias', 'encoder.layer.13.layernorm_before.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.layernorm_after.bias', 'encoder.layer.14.layernorm_after.weight', 'encoder.layer.14.layernorm_before.bias', 'encoder.layer.14.layernorm_before.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.layernorm_after.bias', 'encoder.layer.15.layernorm_after.weight', 'encoder.layer.15.layernorm_before.bias', 'encoder.layer.15.layernorm_before.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.layernorm_after.bias', 'encoder.layer.16.layernorm_after.weight', 'encoder.layer.16.layernorm_before.bias', 'encoder.layer.16.layernorm_before.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.layernorm_after.bias', 'encoder.layer.17.layernorm_after.weight', 'encoder.layer.17.layernorm_before.bias', 'encoder.layer.17.layernorm_before.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.layernorm_after.bias', 'encoder.layer.18.layernorm_after.weight', 'encoder.layer.18.layernorm_before.bias', 'encoder.layer.18.layernorm_before.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.layernorm_after.bias', 'encoder.layer.19.layernorm_after.weight', 'encoder.layer.19.layernorm_before.bias', 'encoder.layer.19.layernorm_before.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.layernorm_after.bias', 'encoder.layer.20.layernorm_after.weight', 'encoder.layer.20.layernorm_before.bias', 'encoder.layer.20.layernorm_before.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.layernorm_after.bias', 'encoder.layer.21.layernorm_after.weight', 'encoder.layer.21.layernorm_before.bias', 'encoder.layer.21.layernorm_before.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.layernorm_after.bias', 'encoder.layer.22.layernorm_after.weight', 'encoder.layer.22.layernorm_before.bias', 'encoder.layer.22.layernorm_before.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.layernorm_after.bias', 'encoder.layer.23.layernorm_after.weight', 'encoder.layer.23.layernorm_before.bias', 'encoder.layer.23.layernorm_before.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type dinov2 to instantiate a model of type vit. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of ViTModel were not initialized from the model checkpoint at facebook/dinov2-giant and are newly initialized: ['encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.layernorm_after.bias', 'encoder.layer.0.layernorm_after.weight', 'encoder.layer.0.layernorm_before.bias', 'encoder.layer.0.layernorm_before.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.layernorm_after.bias', 'encoder.layer.1.layernorm_after.weight', 'encoder.layer.1.layernorm_before.bias', 'encoder.layer.1.layernorm_before.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.layernorm_after.bias', 'encoder.layer.10.layernorm_after.weight', 'encoder.layer.10.layernorm_before.bias', 'encoder.layer.10.layernorm_before.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.layernorm_after.bias', 'encoder.layer.11.layernorm_after.weight', 'encoder.layer.11.layernorm_before.bias', 'encoder.layer.11.layernorm_before.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.12.layernorm_after.bias', 'encoder.layer.12.layernorm_after.weight', 'encoder.layer.12.layernorm_before.bias', 'encoder.layer.12.layernorm_before.weight', 'encoder.layer.12.output.dense.bias', 'encoder.layer.12.output.dense.weight', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.13.layernorm_after.bias', 'encoder.layer.13.layernorm_after.weight', 'encoder.layer.13.layernorm_before.bias', 'encoder.layer.13.layernorm_before.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.14.layernorm_after.bias', 'encoder.layer.14.layernorm_after.weight', 'encoder.layer.14.layernorm_before.bias', 'encoder.layer.14.layernorm_before.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.15.layernorm_after.bias', 'encoder.layer.15.layernorm_after.weight', 'encoder.layer.15.layernorm_before.bias', 'encoder.layer.15.layernorm_before.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.15.output.dense.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.16.layernorm_after.bias', 'encoder.layer.16.layernorm_after.weight', 'encoder.layer.16.layernorm_before.bias', 'encoder.layer.16.layernorm_before.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.17.intermediate.dense.bias', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.17.layernorm_after.bias', 'encoder.layer.17.layernorm_after.weight', 'encoder.layer.17.layernorm_before.bias', 'encoder.layer.17.layernorm_before.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.17.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.18.layernorm_after.bias', 'encoder.layer.18.layernorm_after.weight', 'encoder.layer.18.layernorm_before.bias', 'encoder.layer.18.layernorm_before.weight', 'encoder.layer.18.output.dense.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.19.layernorm_after.bias', 'encoder.layer.19.layernorm_after.weight', 'encoder.layer.19.layernorm_before.bias', 'encoder.layer.19.layernorm_before.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.layernorm_after.bias', 'encoder.layer.2.layernorm_after.weight', 'encoder.layer.2.layernorm_before.bias', 'encoder.layer.2.layernorm_before.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.20.layernorm_after.bias', 'encoder.layer.20.layernorm_after.weight', 'encoder.layer.20.layernorm_before.bias', 'encoder.layer.20.layernorm_before.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.20.output.dense.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.21.layernorm_after.bias', 'encoder.layer.21.layernorm_after.weight', 'encoder.layer.21.layernorm_before.bias', 'encoder.layer.21.layernorm_before.weight', 'encoder.layer.21.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'encoder.layer.22.layernorm_after.bias', 'encoder.layer.22.layernorm_after.weight', 'encoder.layer.22.layernorm_before.bias', 'encoder.layer.22.layernorm_before.weight', 'encoder.layer.22.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.23.layernorm_after.bias', 'encoder.layer.23.layernorm_after.weight', 'encoder.layer.23.layernorm_before.bias', 'encoder.layer.23.layernorm_before.weight', 'encoder.layer.23.output.dense.bias', 'encoder.layer.23.output.dense.weight', 'encoder.layer.24.intermediate.dense.bias', 'encoder.layer.24.intermediate.dense.weight', 'encoder.layer.24.layernorm_after.bias', 'encoder.layer.24.layernorm_after.weight', 'encoder.layer.24.layernorm_before.bias', 'encoder.layer.24.layernorm_before.weight', 'encoder.layer.24.output.dense.bias', 'encoder.layer.24.output.dense.weight', 'encoder.layer.25.intermediate.dense.bias', 'encoder.layer.25.intermediate.dense.weight', 'encoder.layer.25.layernorm_after.bias', 'encoder.layer.25.layernorm_after.weight', 'encoder.layer.25.layernorm_before.bias', 'encoder.layer.25.layernorm_before.weight', 'encoder.layer.25.output.dense.bias', 'encoder.layer.25.output.dense.weight', 'encoder.layer.26.intermediate.dense.bias', 'encoder.layer.26.intermediate.dense.weight', 'encoder.layer.26.layernorm_after.bias', 'encoder.layer.26.layernorm_after.weight', 'encoder.layer.26.layernorm_before.bias', 'encoder.layer.26.layernorm_before.weight', 'encoder.layer.26.output.dense.bias', 'encoder.layer.26.output.dense.weight', 'encoder.layer.27.intermediate.dense.bias', 'encoder.layer.27.intermediate.dense.weight', 'encoder.layer.27.layernorm_after.bias', 'encoder.layer.27.layernorm_after.weight', 'encoder.layer.27.layernorm_before.bias', 'encoder.layer.27.layernorm_before.weight', 'encoder.layer.27.output.dense.bias', 'encoder.layer.27.output.dense.weight', 'encoder.layer.28.intermediate.dense.bias', 'encoder.layer.28.intermediate.dense.weight', 'encoder.layer.28.layernorm_after.bias', 'encoder.layer.28.layernorm_after.weight', 'encoder.layer.28.layernorm_before.bias', 'encoder.layer.28.layernorm_before.weight', 'encoder.layer.28.output.dense.bias', 'encoder.layer.28.output.dense.weight', 'encoder.layer.29.intermediate.dense.bias', 'encoder.layer.29.intermediate.dense.weight', 'encoder.layer.29.layernorm_after.bias', 'encoder.layer.29.layernorm_after.weight', 'encoder.layer.29.layernorm_before.bias', 'encoder.layer.29.layernorm_before.weight', 'encoder.layer.29.output.dense.bias', 'encoder.layer.29.output.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.layernorm_after.bias', 'encoder.layer.3.layernorm_after.weight', 'encoder.layer.3.layernorm_before.bias', 'encoder.layer.3.layernorm_before.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.30.intermediate.dense.bias', 'encoder.layer.30.intermediate.dense.weight', 'encoder.layer.30.layernorm_after.bias', 'encoder.layer.30.layernorm_after.weight', 'encoder.layer.30.layernorm_before.bias', 'encoder.layer.30.layernorm_before.weight', 'encoder.layer.30.output.dense.bias', 'encoder.layer.30.output.dense.weight', 'encoder.layer.31.intermediate.dense.bias', 'encoder.layer.31.intermediate.dense.weight', 'encoder.layer.31.layernorm_after.bias', 'encoder.layer.31.layernorm_after.weight', 'encoder.layer.31.layernorm_before.bias', 'encoder.layer.31.layernorm_before.weight', 'encoder.layer.31.output.dense.bias', 'encoder.layer.31.output.dense.weight', 'encoder.layer.32.intermediate.dense.bias', 'encoder.layer.32.intermediate.dense.weight', 'encoder.layer.32.layernorm_after.bias', 'encoder.layer.32.layernorm_after.weight', 'encoder.layer.32.layernorm_before.bias', 'encoder.layer.32.layernorm_before.weight', 'encoder.layer.32.output.dense.bias', 'encoder.layer.32.output.dense.weight', 'encoder.layer.33.intermediate.dense.bias', 'encoder.layer.33.intermediate.dense.weight', 'encoder.layer.33.layernorm_after.bias', 'encoder.layer.33.layernorm_after.weight', 'encoder.layer.33.layernorm_before.bias', 'encoder.layer.33.layernorm_before.weight', 'encoder.layer.33.output.dense.bias', 'encoder.layer.33.output.dense.weight', 'encoder.layer.34.intermediate.dense.bias', 'encoder.layer.34.intermediate.dense.weight', 'encoder.layer.34.layernorm_after.bias', 'encoder.layer.34.layernorm_after.weight', 'encoder.layer.34.layernorm_before.bias', 'encoder.layer.34.layernorm_before.weight', 'encoder.layer.34.output.dense.bias', 'encoder.layer.34.output.dense.weight', 'encoder.layer.35.intermediate.dense.bias', 'encoder.layer.35.intermediate.dense.weight', 'encoder.layer.35.layernorm_after.bias', 'encoder.layer.35.layernorm_after.weight', 'encoder.layer.35.layernorm_before.bias', 'encoder.layer.35.layernorm_before.weight', 'encoder.layer.35.output.dense.bias', 'encoder.layer.35.output.dense.weight', 'encoder.layer.36.intermediate.dense.bias', 'encoder.layer.36.intermediate.dense.weight', 'encoder.layer.36.layernorm_after.bias', 'encoder.layer.36.layernorm_after.weight', 'encoder.layer.36.layernorm_before.bias', 'encoder.layer.36.layernorm_before.weight', 'encoder.layer.36.output.dense.bias', 'encoder.layer.36.output.dense.weight', 'encoder.layer.37.intermediate.dense.bias', 'encoder.layer.37.intermediate.dense.weight', 'encoder.layer.37.layernorm_after.bias', 'encoder.layer.37.layernorm_after.weight', 'encoder.layer.37.layernorm_before.bias', 'encoder.layer.37.layernorm_before.weight', 'encoder.layer.37.output.dense.bias', 'encoder.layer.37.output.dense.weight', 'encoder.layer.38.intermediate.dense.bias', 'encoder.layer.38.intermediate.dense.weight', 'encoder.layer.38.layernorm_after.bias', 'encoder.layer.38.layernorm_after.weight', 'encoder.layer.38.layernorm_before.bias', 'encoder.layer.38.layernorm_before.weight', 'encoder.layer.38.output.dense.bias', 'encoder.layer.38.output.dense.weight', 'encoder.layer.39.intermediate.dense.bias', 'encoder.layer.39.intermediate.dense.weight', 'encoder.layer.39.layernorm_after.bias', 'encoder.layer.39.layernorm_after.weight', 'encoder.layer.39.layernorm_before.bias', 'encoder.layer.39.layernorm_before.weight', 'encoder.layer.39.output.dense.bias', 'encoder.layer.39.output.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.layernorm_after.bias', 'encoder.layer.4.layernorm_after.weight', 'encoder.layer.4.layernorm_before.bias', 'encoder.layer.4.layernorm_before.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.layernorm_after.bias', 'encoder.layer.5.layernorm_after.weight', 'encoder.layer.5.layernorm_before.bias', 'encoder.layer.5.layernorm_before.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.layernorm_after.bias', 'encoder.layer.6.layernorm_after.weight', 'encoder.layer.6.layernorm_before.bias', 'encoder.layer.6.layernorm_before.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.layernorm_after.bias', 'encoder.layer.7.layernorm_after.weight', 'encoder.layer.7.layernorm_before.bias', 'encoder.layer.7.layernorm_before.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.layernorm_after.bias', 'encoder.layer.8.layernorm_after.weight', 'encoder.layer.8.layernorm_before.bias', 'encoder.layer.8.layernorm_before.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.layernorm_after.bias', 'encoder.layer.9.layernorm_after.weight', 'encoder.layer.9.layernorm_before.bias', 'encoder.layer.9.layernorm_before.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete 40\n"
     ]
    }
   ],
   "source": [
    "'DINO small (l = 12, d = 384, h = 6, patches = 8 ; 21M parameters)'\n",
    "model_name = 'facebook/dino-vits8'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dino-vitb8'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dino-vits16'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dino-vitb16'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dinov2-small'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dinov2-base'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dinov2-large'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)\n",
    "\n",
    "model_name = 'facebook/dinov2-giant'\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = ViTModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'save'\n",
    "with open(dir, 'wb') as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
