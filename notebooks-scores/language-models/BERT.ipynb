{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "from transformers import AutoModel, BertModel, DistilBertModel, AutoConfig\n",
    "from utils.funs import create_dict\n",
    "from utils.scores import get_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models, dir = create_dict('language-models', 'BERT.pkl')\n",
    "\n",
    "path = [\"encoder.layer[\", \n",
    "        \"].attention.self.query.weight\", \n",
    "        \"].attention.self.key.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete \n",
      "100% processing complete \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniconda/base/envs/attention-geometry/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processing complete \n",
      "100% processing complete \n",
      "100% processing complete 12\n",
      "100% processing complete 24\n",
      "100% processing complete \n"
     ]
    }
   ],
   "source": [
    "'BERT tiny (l = 2, d = 128, h = 2 ; 4.40M parameters)'\n",
    "model_name = \"google/bert_uncased_L-2_H-128_A-2\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "'BERT mini (l = 4, d = 256, h = 4 ; 11.3M parameters)'\n",
    "model_name = \"google/bert_uncased_L-4_H-256_A-4\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "'BERT small (l = 4, d = 512, h = 8 ; 29.1M parameters)'\n",
    "model_name = \"google/bert_uncased_L-4_H-512_A-8\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "'BERT medium (l = 8, d = 512, h = 8 ; 41.7M parameters)'\n",
    "model_name = \"google/bert_uncased_L-8_H-512_A-8\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "'BERT base (l = 12, d = 768, h = 12 ; 110M parameters)'\n",
    "model_name = \"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "'BERT large (l = 24, d = 1024, h = 16 ; 340M parameters)'\n",
    "model_name = \"bert-large-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")\n",
    "\n",
    "path = [\"transformer.layer[\", \n",
    "        \"].attention.q_lin.weight\", \n",
    "        \"].attention.k_lin.weight\"]\n",
    "'DistillBERT base model (l = 6, d = 768, h = 12 ; tot num parameters 66M)'\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "model = DistilBertModel.from_pretrained(model_name)\n",
    "models = get_scores(models,\n",
    "                    model_name, model, config,\n",
    "                    path, download_model = True,\n",
    "                    attn_type = \"BERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'save'\n",
    "with open(dir, 'wb') as file:\n",
    "    pickle.dump(models, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "attention-geometry",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
